{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNSE4DpaYPhA3DUPc5/PAmX"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T_Bvm_CGODvj"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyMuPDF sentence-transformers transformers scikit-learn openai"
      ],
      "metadata": {
        "id": "hfj71VgZOIv0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import fitz\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from openai import OpenAI"
      ],
      "metadata": {
        "id": "ooXCKm1wOIt4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_path = \"/content/Human-Nutrition-2020.pdf\""
      ],
      "metadata": {
        "id": "a_jp9CgKOIrz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_text_from_pdf(pdf_path):\n",
        "    doc = fitz.open(pdf_path)\n",
        "    text = \"\"\n",
        "    for page in doc:\n",
        "        text += page.get_text()\n",
        "    return text\n",
        "\n",
        "pdf_text = extract_text_from_pdf(pdf_path)"
      ],
      "metadata": {
        "id": "Frv5zzK5OIpu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "    text = text.replace('\\n', ' ')\n",
        "    text = ' '.join(text.split())\n",
        "    return text\n",
        "\n",
        "cleaned_text = clean_text(pdf_text)"
      ],
      "metadata": {
        "id": "WGvP6FvIOInm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chunk_text(text, chunk_size=1000, overlap=100):\n",
        "    chunks = []\n",
        "    start = 0\n",
        "    while start < len(text):\n",
        "        end = start + chunk_size\n",
        "        chunk = text[start:end]\n",
        "        chunks.append(chunk)\n",
        "        start += chunk_size - overlap\n",
        "    return chunks\n",
        "\n",
        "chunks = chunk_text(cleaned_text)\n",
        "print(f\"Total chunks: {len(chunks)}\")"
      ],
      "metadata": {
        "id": "giRKOzDyOIlI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "tokens = tokenizer(\n",
        "    chunks,\n",
        "    truncation=True,\n",
        "    padding='max_length',\n",
        "    max_length=512,\n",
        "    return_tensors='pt'\n",
        ")\n",
        "\n",
        "print(tokens['input_ids'].shape)"
      ],
      "metadata": {
        "id": "hU7x513AOIjX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "embeddings = model.encode(chunks, show_progress_bar=True)"
      ],
      "metadata": {
        "id": "1dhM4LHQOIhL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.save('embeddings.npy', embeddings)\n",
        "\n",
        "loaded_embeddings = np.load('embeddings.npy')\n",
        "print(loaded_embeddings.shape)\n",
        "\n",
        "query = input(\"Enter your question: \")\n",
        "query_embedding = model.encode([query])\n",
        "\n"
      ],
      "metadata": {
        "id": "4HXRhNf9OIe_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "similarities = cosine_similarity(query_embedding, loaded_embeddings)\n",
        "top_k_idx = similarities[0].argsort()[-5:][::-1]\n",
        "\n",
        "for i, idx in enumerate(top_k_idx):\n",
        "    score = similarities[0][idx]\n",
        "    chunk = chunks[idx]\n",
        "    print(f\"Chunk {i+1} (score: {score:.4f}): {chunk[:500]}...\\n\")\n",
        "\n",
        "retrieved_chunks = [chunks[i] for i in top_k_idx]\n",
        "\n",
        "context = \"\\n\\n\".join(retrieved_chunks)\n",
        "\n",
        "prompt = f\"\"\"Answer the following question based on the provided context.\n",
        "If the answer cannot be found in the context, say you don't know.\n",
        "\n",
        "Question: {query}\n",
        "\n",
        "Context: {context}\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "EzUPYn2qOIcO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client = OpenAI(api_key=\"\")\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "        {\"role\": \"user\", \"content\": prompt}\n",
        "    ],\n",
        "    temperature=0\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "id": "4bgGYWuxOIY3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}